{"componentChunkName":"component---src-templates-post-jsx","path":"/ut/ut7/ta1","result":{"data":{"markdownRemark":{"html":"<p>En este artículo se explorarán las métricas y formas de evaluación que tenemos en RapidMiner para una problemática de clasificación</p>\n<h1>Datos</h1>\n<p>Para comenzar, utilizaremos datos generados aleatoriamente con el operador de RapidMiner llamado <code class=\"language-text\">Generate Direct Mailing Data</code>. Este nos crea una tabla de datos que contiene los siguientes atributos:</p>\n<ul>\n<li>label</li>\n<li>name</li>\n<li>age</li>\n<li>lifestyle</li>\n<li>zip code</li>\n<li>family status</li>\n<li>car</li>\n<li>sports</li>\n<li>earnings</li>\n</ul>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut7/ta/ta1/data.png?raw=true\" alt=\"data\"></p>\n<p>Tomaremos el atributo label como nuestra variable objetivo del problema, la cual nos dice si se tuvo respuesta de esta persona o no.</p>\n<h1>Pipeline</h1>\n<p>Se usará el siguiente pipeline en RapidMiner:\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut6/ta/ta3/pipeline.png?raw=true\" alt=\"pipeline\">\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut6/ta/ta3/validation.png?raw=true\" alt=\"validation\"></p>\n<p>Como se puede ver en la imagen, este pipeline consiste de:</p>\n<ul>\n<li>Obtener los datos</li>\n<li>Transformar la variable objetivo a binominal</li>\n<li>Separar los datos en entrenamiento y test (se realizó una separación de 80% vs 20%)</li>\n<li>\n<p>Separar el conjunto de entrenamiento en entrenamiento y validación (se realizó una separación de 70% vs 30%)</p>\n<ul>\n<li>Dentro de la validación tenemos el entrenamiento de un modelo de Naive Bayes, y su evaluación de performance sobre el conjunto de validación</li>\n</ul>\n</li>\n<li>Una vez entrenado el modelo se aplica la evaluación sobre el conjunto de testing y se crean lift charts sobre este resultado.</li>\n</ul>\n<h1>Analisis</h1>\n<p>En el siguiente apartado mostraremos los resultados de cada métrica y explicaremos su uso.</p>\n<h2>Accuracy</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut7/ta/ta1/accuracy.png?raw=true\" alt=\"accuracy\"></p>\n<p>El accuracy es la fracción de predicciones correctas, es decir cuántos casos evaluó correctamente el modelo de todos los casos que tenemos.</p>\n<p>Como vemos en la imagen obtuvimos un 77,96% de accuracy.</p>\n<p>A su vez la imagen nos muestra una matriz de confusión donde podemos ver más información.</p>\n<h3>Matriz de confusion</h3>\n<p><img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\" alt=\"confussion_matrix\">\nImagen tomada de: <a href=\"https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html\">What is Confusion Matrix and Advanced Classification Metrics?</a></p>\n<p>Una matriz de confusión es una matriz la cual nos muestra los valores que el modelo predijo y en qué situaciones están estos, es decir si son categorizados como True Positives, True Negatives, False Positive y False Negatives. Estos conceptos los veremos más adelante.</p>\n<h3>Precision</h3>\n<p>La precisión es una métrica calculada en base a la siguiente fórmula: TP/(TP+FP), donde TP son los True positivo, y FP los False Positive, mas adelante explicaremos estos en detalle, pero lo que busca la métrica de precisión es la frecuencia con la cual se predijo correctamente la variable objetivo. Es decir, que tan bien se clasificó como respuesta los mensajes entre todos los clasificados como respuesta.</p>\n<h3>Recall</h3>\n<p>El recall es lo que veremos más adelante como la Sensitivity.</p>\n<h2>AUC y ROC</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut7/ta/ta1/auc.png?raw=true\" alt=\"auc\"></p>\n<p>AUC es una métrica de evaluación la cual nos muestra todos los valores de umbral posibles a tomar en cuenta. Esto nos estará dando información de que tan bien se evalúa de que un ejemplo positivo sea realmente positivo contar que un ejemplo positivo sea evaluado como negativo en diferentes umbrales.</p>\n<h2>False positive</h2>\n<p>Las métricas de False Positive en este caso dieron que 408 ejemplos fueron tomados como tales (como se ve en la matriz de confusión de arriba). El caso de False Positive es clasificar una clase no positiva como positiva, en este caso, es decir que una persona de la cual no se tuvo respuesta clasificarla como que se tuvo, esto sería un falso positivo para la variable objetivo de tener respuesta.</p>\n<h2>False negative</h2>\n<p>Las métricas de False Negative en este caso dieron que 121 ejemplos fueron tomados como tales (como se ve en la matriz de confusión de arriba). El caso de False Negative es clasificar una clase positiva como no positiva, en este caso, es decir que una persona de la cual se tuvo respuesta clasificarla como que no se tuvo.</p>\n<h2>True positive</h2>\n<p>Este es el caso que buscamos, que una clase positiva, es decir un mail que se tuvo respuesta fue clasificado como tal, para esto se tuvo 632 casos.</p>\n<h2>True negative</h2>\n<p>Este es el caso que buscamos también, que una clase no positiva sea evaluada como no positiva, para esto se tuvieron 1239 casos.</p>\n<h2>Sensitivity</h2>\n<p>La sensibilidad es calculada como vimos más arriba en la matriz de confusión, esta es una métrica que evalúa qué tan bien se identifican correctamente un caso positivo</p>\n<h2>Specificity</h2>\n<p>La especificidad por otro lado es que tan bien evalúa la clase negativa correctamente.</p>\n<h2>Lift Chart</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut7/ta/ta1/lift.png?raw=true\" alt=\"lift\"></p>\n<p>En la imagen de arriba podemos ver la gráfica llamada Lift Chart, la cual nos muestra cuantos elementos son correctamente evaluados mientras se va aumentando el grado de confianza con el que modelo predice.</p>\n<h1>Archivos</h1>\n<ul>\n<li><a href=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut7/ta/ta1/ut7ta1.rmp\">Archivo de RapidMiner</a></li>\n</ul>","frontmatter":{"date":"2021-11-23","title":"Métricas y evaluación de modelos en clasificación","tags":["Ajuste, evaluación y sintonía de modelos","RapidMiner","Accuracy","False Positive","False Negative","True Positive","True Negative","Sensitivity","Specificity","AUC","ROC","Validacion","Lift Chart","Matriz de confusion","Precision","Recall"],"cover":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAFFxjzeAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABbElEQVQoz11S207CQBTcX/aFaFToHR5M1EhEAy0XocXfMfFBYxRiokBKK1B4Hc85S8vlYbq7s7Nnz0xXnda/YXYSGO05VDXMUBuuUY0yKGbNDrPDDFViZTtfMJzBEqrix7BEqmEEUz6yFqU3SLWaC/JHsCWEdLoJyo+/OL8e4exqjNrzBheNd9pca/CdUX759hT3eFJ/RaU5gtGJpZGiYul2XDSzw1yDXJrBDJWAfJVuPlG++4Hlk8Cfw2iN4YUrXSnUcJ4WUHydF620dyb7sfQpaxJ7BJezyAmG01+i9PCFy8YLXKrKgnx/G2lWEDqvDXYRaShu2Ago4W4qRni0enpu02j3/ij9VHieH0JrrS4HEFNSKZQXLuEQ6VE7VnMK834Cu02COo1BIl7s9gfM1htZWIhfDiUH2xBQHUlx/7/s/1kOjYXl1kS64G74bRQJR3nh3ZurHbyy6DgjDb6ZD7mDBG5/BnZ0kOeR/h/ddSvYAFHcUgAAAABJRU5ErkJggg==","aspectRatio":2.2018348623853212,"src":"/static/d7362285fd95b9a155b37467733e8c39/d10be/pipeline.png","srcSet":"/static/d7362285fd95b9a155b37467733e8c39/0d3b3/pipeline.png 480w,\n/static/d7362285fd95b9a155b37467733e8c39/263b6/pipeline.png 960w,\n/static/d7362285fd95b9a155b37467733e8c39/d10be/pipeline.png 1920w,\n/static/d7362285fd95b9a155b37467733e8c39/7e33e/pipeline.png 2244w","srcWebp":"/static/d7362285fd95b9a155b37467733e8c39/dc7e7/pipeline.webp","srcSetWebp":"/static/d7362285fd95b9a155b37467733e8c39/83f4f/pipeline.webp 480w,\n/static/d7362285fd95b9a155b37467733e8c39/ce114/pipeline.webp 960w,\n/static/d7362285fd95b9a155b37467733e8c39/dc7e7/pipeline.webp 1920w,\n/static/d7362285fd95b9a155b37467733e8c39/86cbd/pipeline.webp 2244w","sizes":"(max-width: 1920px) 100vw, 1920px"},"resize":{"src":"/static/d7362285fd95b9a155b37467733e8c39/73f08/pipeline.png"}}}}}},"pageContext":{"pathSlug":"/ut/ut7/ta1","prev":{"frontmatter":{"path":"/ut/ut6/ta3","title":"Usando Random Forest y AdaBoost en RapidMiner","tags":["Ensambles","Random Forest","RapidMiner","Cross Validation","Performance","AdaBoost","Chronic kidney disease Dataset"]}},"next":{"frontmatter":{"path":"/ca/ames-housing","title":"Caso de estudio: Ames Housing","tags":["Caso de estudio","Tratamiento previo de los datos y fundamentos de los algoritmos de ML","Algoritmos lineales","Algoritmos no lineales","Aprendizaje no supervisado y Métodos de clustering","Ensambles","Ajuste, evaluación y sintonía de modelos","Random Forest","Boosting","PCA","Outlier","Kaggle","Split data","Pandas","Matplotlib","Seaborn","Scikit-learn","Selección de Atributos","Vote","Gradient Boosting","Missing values","Ruido"]}}}},"staticQueryHashes":["1830426702"]}