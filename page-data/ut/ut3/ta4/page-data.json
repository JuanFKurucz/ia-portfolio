{"componentChunkName":"component---src-templates-post-jsx","path":"/ut/ut3/ta4","result":{"data":{"markdownRemark":{"html":"<p>En este artículo se busca utilizar regresión logística en RapidMiner para atacar la problemática de un cardiólogo para el apoyo de diagnóstico en un centro de salud.</p>\n<h1>Entendimiento del problema</h1>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/cover.png?raw=true\" alt=\"escenario\"></p>\n<p>El escenario descrito anteriormente consiste en lograr determinar los riesgos de los problemas coronarios. Específicamente lograr identificar posibles pacientes que puedan tener un segundo ataque cardiaco para poder prevenir estos con cambios en su estilo de vida.</p>\n<h1>Comprensión de los datos</h1>\n<p>Se nos ofrecen los siguientes archivos de datos:</p>\n<ul>\n<li><a href=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/cardiac-training.csv\">cardiac-training.csv</a></li>\n<li><a href=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/cardiac-scoring.csv\">cardiac-scoring.csv</a></li>\n</ul>\n<p>A su vez se nos otorga una descripción de los mismos:</p>\n<ul>\n<li><strong>Edad</strong>: la edad en años redondeada al entero más cercano. </li>\n<li><strong>Estado_civil</strong>: codificado mediante un número: 0 = soltero; 1 = casado, 2 = divorciado y 3 = viudo.</li>\n<li><strong>Sexo</strong>: 0 = femenino; 1= masculino.</li>\n<li><strong>Categoria_Peso</strong>: el peso de la persona, categorizado en uno de tres posibles niveles: 0 = normal; 1 = sobrepeso; 2 = obeso.</li>\n<li><strong>Colesterol</strong>: nivel de colesterol de la persona, tal como se ha registrado en el momento del tratamiento indicado cuando su más reciente ataque al corazón.</li>\n<li><strong>Manejo_stress</strong>: un atributo binario que indica si el paciente ha participado previamente de cursos de manejo del estrés: 0 = no; 1 = si.</li>\n<li><strong>Trat_ansiedad</strong>: valor entre 0 y 100 indicativo del nivel natural de estrés de cada persona y de su habilidad para manejar este estrés. Poco tiempo después de que la persona se recupera de su primer ataque, se le administró un test de ansiedad natural estándar. Los valores están tabulados en incrementos de 5. Un valor de 0 indicaría que la persona nunca siente ansiedad, presión o estrés en ninguna situación, mientras que un valor de 100 indicaría que la persona vive en un estado continuo de sobrecarga e incapaz de lidiar con su situación.</li>\n<li><strong>2do<em>Ataque</em>Corazon</strong>: Este atributo existe solamente en el dataset de entrenamiento. Es la variable objetivo o de predicción (“label” en RM). En el dataset de entrenamiento, este atributo contiene “SI” para aquellos individuos que han sufrido un segundo ataque al corazón, y “no” en caso contrario.</li>\n</ul>\n<p>Las descripciones de los atributos parecen ser suficientes como para indagar en profundidad.</p>\n<h1>Pipeline</h1>\n<p>Iremos paso a paso en diferentes puntos del pipeline.</p>\n<h2>1. Importar los datos de entrenamiento (“cardiac-training.csv”).</h2>\n<p>Dado los datos, al importar tendremos que verificar que la primera fila se configura como nombres de los atributos. Después de esto tenemos que establecer el atributo “2do<em>Ataque</em>Corazon” como 0 y 1 dado que es una problemática de regresión lineal y necesitamos números reales.</p>\n<p>A su vez tenemos otros atributos que tenemos que transformar a binominales como \"Sexo\"\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/2.2.png?raw=true\" alt=\"2.2\"></p>\n<p>A continuación tendremos que establecer al atributo “2do<em>Ataque</em>Corazon” como variable de predicción, o agregar un “set role” posterior</p>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/3.png?raw=true\" alt=\"3\"></p>\n<h2>2. Importa el archivo de test / evaluación / predicción (“cardiac-scoring.csv”).</h2>\n<p>A continuación importamos el conjunto de datos de evaluación llamado “cardiac-scoring.csv”, tendremos que verificar que el tipo de datos de atributos es integer. Ya que todas las columnas son los inputs que tomará el modelo para poder lograr la predicción, como las anteriores eran integers, estas también lo tendrán que ser.</p>\n<h2>3. Modelar, entrenar y evaluar</h2>\n<p>Para esto debemos hacernos algunas preguntas antes:</p>\n<ol>\n<li><strong>¿Cómo son, comparativamente, estos rangos?</strong>\nSe tienen diferentes rangos, los cuales podrían dar problemas a la hora de lograr clasificar correctamente, un escalado podría ser necesario.</li>\n<li><strong>¿Están todos los atributos de los ejemplos de evaluación / predicción en los rangos de los atributos del dataset de entrenamiento?</strong>\nSi están</li>\n<li><strong>¿Por qué tenemos que verificar esto?</strong>\nPara ver si es necesario rellenar con determinados valores estos atributos, o a cuáles darles más prioridad en el entrenamiento si sabemos que futuros atributos no vendrán o son más costosos de obtener.</li>\n<li><strong>¿Hay más tareas de preparación previa de los datos para hacer?</strong>\nSe podría evaluar la distribución de los datos, para normalizar y escalar bien estos. Además se podría hacer detección de outliers y arreglos de valores faltantes si es que los hay.</li>\n</ol>\n<h1>Creación del Pipeline</h1>\n<p>A continuación veremos capturas del Pipeline creado</p>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ej2.0.png?raw=true\" alt=\"ej2.0.png\">\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ej2.1.png?raw=true\" alt=\"ej2.1.png\"></p>\n<h1>Resultados</h1>\n<p>A continuación veremos los resultados y analizaremos estos en profundidad</p>\n<h2>Resultados del pipeline</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ej2.2.png?raw=true\" alt=\"ej2.2.png\">\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ej2.3.png?raw=true\" alt=\"ej2.3.png\"></p>\n<h2>Análisis de resultados</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ej3.1.png?raw=true\" alt=\"ej3.1.png\"></p>\n<p>Hombre, soltero, 61 años, con sobrepeso, pero el colesterol es bajo (139 y la media es 178).</p>\n<ul>\n<li>está en el medio de la clase para tratamiento de ansiedad (50) y ha participado en manejo del estrés</li>\n<li>el modelo nos da xx % de confianza en que la predicción “No” es correcta, lo que nos deja un (1-xx %) de duda.</li>\n</ul>\n<h3>¿Cuál sería la decisión del Dr. García para este paciente?</h3>\n<p>Ya que existe una confianza del 91,84% de qué va a tener un segundo ataque cardíaco, esta confianza es un número muy elevado por lo cual es precavido proceder con un tratamiento para evitar este 2.º ataque cardíaco.</p>\n<h2>2. Veamos la tupla 11</h2>\n<p>Hombre, divorciado, 66 años, está por encima de la media en todos los predictores (analizar)</p>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ej3.2.png?raw=true\" alt=\"ej3.2.png\"></p>\n<p>En este caso nuestro modelo predijo con 99,3% de confianza que no va a tener un 2do ataque cardiaco.</p>\n<h2>3. ¿Cuál sería la decisión del Dr. García para este paciente?</h2>\n<ul>\n<li>¿Cómo usar la predicción en un caso de consultoría o desarrollo de un sistema real?</li>\n</ul>\n<p>Esta predicción debería ser usada como una herramienta adicional del doctor. En la cual se ingresan los atributos y se obtiene un porcentaje de confianza, si estos son elevados el doctor podrá asegurarse de una calidad de respuesta, en caso de que la confianza no sea suficiente tendrá que ir por otros caminos.</p>\n<ul>\n<li>¿cuántos pacientes tienen predicción de ataque cardíaco? Tener en cuenta los niveles de confianza</li>\n</ul>\n<p>340 pacientes tienen predicción de ataque cardiaco de un total de 690. Teniendo en cuenta que el margen de nivel de confianza es el 50%, es decir que se dice que se tiene o no un ataque cardiaco si la confianza de esto es mayor o igual  al 50%.</p>\n<ul>\n<li>¿cómo podríamos en RM analizar la performance global del modelo?</li>\n</ul>\n<p>Con una separación de validación o en caso de pocos datos con un cross validación. Lo que es seguro es que es necesario un conjunto de datos no visto por el modelo para ver como performa con datos nunca vistos.</p>\n<h1>Archivos:</h1>\n<ul>\n<li><a href=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ta4-load-training.rmp\">ta4-load-training.rmp</a></li>\n<li><a href=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut3/ta/ta4/ta4-all.rmp\">ta4-all.rmp</a></li>\n</ul>","frontmatter":{"date":"2021-09-07","title":"Utilización de Regresión Logística en RapidMiner","tags":["Algoritmos lineales","Regresión Logística","RapidMiner","Pipeline","Cardiac Dataset"],"cover":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAHDUk5wAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABXklEQVQoz11S2VbCUAzsL4tCy+LC4pMbYMHKUeGgfyVHLK11LeIXxMzcphx9CMnNnZuZDPVa168ShKnUx6l4rUgPo1SO7r7Ea1xlrlte48cPV9IYv0hTobVB7JpsKBxNZA9DgKwNY+Zqf6kDFWUBhvY0d89thDEiB/qqrj2ADm4+VJsK3T1/4sggTMS/XBFsZ1JpeM0oE4DRsLquekwg6u78G3slPPhDJxQScAbt/uSdGrvzTQEsLv3Q0dojo6VlbAyeuS4tUI0WBt56qwCAjDIoslnTe/gRD5OqfTcRk+EAp6skqxF7F0uyoDaX7N5q+t2avMkfz8Ecupp9OBVlJHC97T2VzfIyH0NhUPy9OyePUjldkKlytihVIsMsDLFtzDRsZEbiHb1xj9zKYOd3NIhLEMJWRR81elDND5A5o2L+z27FRA5vP6UzW1N6m3ldnjtWT/Pi3q35P3r3G/kF31xN/vbgGwUAAAAASUVORK5CYII=","aspectRatio":1.951219512195122,"src":"/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/d10be/cover.png","srcSet":"/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/0d3b3/cover.png 480w,\n/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/263b6/cover.png 960w,\n/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/d10be/cover.png 1920w,\n/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/91b15/cover.png 1952w","srcWebp":"/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/dc7e7/cover.webp","srcSetWebp":"/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/83f4f/cover.webp 480w,\n/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/ce114/cover.webp 960w,\n/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/dc7e7/cover.webp 1920w,\n/ia-portfolio/static/b359db9e1b8989644d478a574ba39f77/cd5df/cover.webp 1952w","sizes":"(max-width: 1920px) 100vw, 1920px"},"resize":{"src":"/static/b359db9e1b8989644d478a574ba39f77/73f08/cover.png"}}}}}},"pageContext":{"pathSlug":"/ut/ut3/ta4","prev":{"frontmatter":{"path":"/ut/ut3/ta2","title":"Utilización de Regresión Lineal en RapidMiner","tags":["Algoritmos lineales","Regresión lineal","RapidMiner","Residuo","Performance","Entrenamiento","Validación","Pipeline","Colinear features","Bias","Feature selection","UCI","Housing Dataset"]}},"next":{"frontmatter":{"path":"/ut/ut3/ta6","title":"Utilización de Análisis Discriminante Lineal en RapidMiner","tags":["Algoritmos lineales","Análisis Discriminante Lineal","RapidMiner","Sports Dataset","Outlier","Normalización","Filtrado"]}}}},"staticQueryHashes":["1830426702"]}