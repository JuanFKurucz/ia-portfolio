{"componentChunkName":"component---src-templates-post-jsx","path":"/pd/ut4-2/pd3","result":{"data":{"markdownRemark":{"html":"<p>En este artículo se simulará el algoritmo de KNN en una hoja de cálculo de Excel.</p>\n<h1>Algoritmo</h1>\n<p>El algoritmo de KNN se basa en encontrar los K vecinos más cercanos, para esto utilizaremos la distancia euclidia</p>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4-2/pd/pd3/distancia.png?raw=true\" alt=\"distancia\"></p>\n<h1>Datos</h1>\n<p>Se utilizará el siguiente conjunto de datos\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4-2/pd/pd3/data.png?raw=true\" alt=\"data\"></p>\n<p>Que al graficarlo se visualiza de la siguiente forma\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4-2/pd/pd3/grafica.png?raw=true\" alt=\"grafica\"></p>\n<h1>Prediccion</h1>\n<p>Para realizar la predicción se utilizan los datos del conjunto de datos y en base a estos se elige la clase más presente en los K vecinos más cercanos.</p>\n<p>Para esto tomaremos el valor:\nX1 = 8.093607318 X2 = 3.365731514 Y = 1</p>\n<p>El resultado de la predicción es:\n<img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4-2/pd/pd3/pred.png?raw=true\" alt=\"pred\"></p>\n<h1>Archivo</h1>\n<p><a href=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4-2/pd/pd3/excel.xlsx?raw=true\">Archivo de excel</a></p>","frontmatter":{"date":"2021-10-29","title":"Simulando el algoritmo de KNN en Excel","tags":["Algoritmos no lineales","KNN","Excel"],"cover":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAAHeV37IAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABkUlEQVQ4y11TPXPCMAz1f+4dDF1ovhw69K60Q0cIIQR+VO9g6VZonNLR1ZMsJ2HQyVak5/ckxTy8fPr56uznb2dv8vrHF03PZhDhKG62pUi2vXqLS+O83SPNeWMbORTB44NhxNXJR/9OOPiS1R1nZrXzZftLwXYoY4+H+KB4wZtkc4mP5DvAdD7ZdvI47mRIFpptP0oW+KdKEnB+/PgSxMWm8zmRSqurT6kQyDCcFcjMWIrKUWnB0CaSN3s9SQOFm2PkpBKeRYjhebxmVIBKt6EAfeE7+O9CIoiXrRDPudUuzKH3i/WFuRuR70aI4/6FYiCyUjLlmpFPK0HBHU9zYtEMKDphexdjMThgmMvjny8P5A83tpLs+Sh+Gc/Iu8WcaFTL9VgKUCoClagnaMonDPrh28hivI2aL6JtP2wv1gLzQRL2KAtroiOA11hsQdiOCSCA0lrMxtG4yfYWo57FVZ/MuZYtKe8kT8d5Jy+wTOtRi1Qyeqj/M0arDHipKVGXHeeE1KBQV4Nbsv5mb2kgIPYPzmQmDPamrn0AAAAASUVORK5CYII=","aspectRatio":1.5946843853820598,"src":"/ia-portfolio/static/35d0cece30e86e0260c05562f795c7ef/742bf/grafica.png","srcSet":"/ia-portfolio/static/35d0cece30e86e0260c05562f795c7ef/0d3b3/grafica.png 480w,\n/ia-portfolio/static/35d0cece30e86e0260c05562f795c7ef/742bf/grafica.png 912w","srcWebp":"/ia-portfolio/static/35d0cece30e86e0260c05562f795c7ef/3f994/grafica.webp","srcSetWebp":"/ia-portfolio/static/35d0cece30e86e0260c05562f795c7ef/83f4f/grafica.webp 480w,\n/ia-portfolio/static/35d0cece30e86e0260c05562f795c7ef/3f994/grafica.webp 912w","sizes":"(max-width: 912px) 100vw, 912px"},"resize":{"src":"/static/35d0cece30e86e0260c05562f795c7ef/73f08/grafica.png"}}}}}},"pageContext":{"pathSlug":"/pd/ut4-2/pd3","prev":{"frontmatter":{"path":"/ut/ut4-2/ta10","title":"Operadores de selección de atributos en RapidMiner","tags":["Algoritmos no lineales","Selección de Atributos","RapidMiner","Iris Dataset","Forward Selection","Backward Elimination","Evolutivo","Sonar Dataset","Performance","Cross validation","Naive bayes"]}},"next":{"frontmatter":{"path":"/ut/ut5/ta3","title":"Evaluando PCA clustering en RapidMiner","tags":["Aprendizaje no supervisado y Métodos de clustering","PCA","RapidMiner","K-means","Selección de Atributos"]}}}},"staticQueryHashes":["1830426702"]}