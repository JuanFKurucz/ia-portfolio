{"componentChunkName":"component---src-templates-post-jsx","path":"/pd/ut4/pd2","result":{"data":{"markdownRemark":{"html":"<p>En este articulo se estudiara el pipeline creado en KNIME el cual puede ser consultado <a href=\"https://hub.knime.com/knime/spaces/Examples/latest/04_Analytics/05_Regressions/01_Learning_a_Simple_Regression_Tree~Ko5y95_spbdxsW5i\">How to Use the Simple Regression Tree</a></p>\n<h1>Estudio del modelo</h1>\n<p>El proyecto implementa un pipeline de entrenamiento y evaluación de un modelo de regresión tomando como atributo objetivo el petal_width (ancho del pétalo) y el resto de los atributos como atributos de entrenamiento.</p>\n<h1>Propiedades del operador “File Reader”.</h1>\n<p>Este operador carga el conjunto de datos de IRIS de una ruta provista por knime. Es similar al operador de Retrieve de RapidMiner, en este mismo se pueden realizar operaciones similares como cargar un conjunto de datos desde un archivo con configuraciones específicas del mismo y seleccionar el tipo de sus columnas</p>\n<h2>Tipos de datos de los atributos del dataset y variable de predicción</h2>\n<p>Los atributos de números (sepal<em>width, sepal</em>length, petal<em>width, petal</em>length) se definen como Number (double), la clase se define como String. No se define la variable de predicción en la carga del conjunto de datos, se define posteriormente en el modelo.</p>\n<h1>Operador “Partitioning”</h1>\n<p>Nos ofrece hacer una partición del conjunto de datos en entrenamiento y evaluación. Por una cantidad fija de datos o un porcentaje relativo. A su vez podemos reordenar este conjunto de datos de forma aleatoria aplicando diferentes métodos.</p>\n<p>Este operador es similar al operador de Split data, el cual tiene las mismas opciones que este.</p>\n<h1>Operador “Simple Regression Tree Learner”</h1>\n<h2>Predictores</h2>\n<p>Soporta sepal<em>length, sepal</em>width, petal<em>length y petal</em>width</p>\n<h2>Variables de predicción</h2>\n<p>Los tipos de predictores que soporta son numéricos.</p>\n<h2>Algoritmo base</h2>\n<p>Utiliza un algoritmo basado en ​​\"Classification and Regression Trees\" (Breiman et al, 1984).</p>\n<h2>Parámetros configurables</h2>\n<ul>\n<li>Opciones de árbol, si usar separaciones binarias.</li>\n<li>Métodos para tratar con datos faltantes</li>\n<li>Limitar el número de niveles del árbol</li>\n<li>Establecer el mínimo de separación del tamaño del nodo</li>\n<li>Establecer el mínimo tamaño del nodo</li>\n</ul>\n<h2>Regresión</h2>\n<p>El valor que se predice es el valor de la hoja del árbol el cual es el promedio de las variables objetivo en esa hoja.</p>\n<h1>Operador “Simple Regression Tree Predictor”</h1>\n<h2>Entradas y salidas</h2>\n<p>Las entradas son el modelo entrenado y un conjunto de datos a evaluar, en este caso el set de test.</p>\n<h2>Parámetros</h2>\n<p>Acepta cambiar el nombre de la columna de predicción</p>\n<h1>Operador “Line Plot”</h1>\n<h2>Grafica de rendimiento del algoritmo AD regresión</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4/pd/pd2/plot.png?raw=true\" alt=\"plot\"></p>\n<h2>Parámetros disponibles</h2>\n<p>Se puede asignar el límite de filas a mostrar en el plot, y una opción para ignorar columnas con un valor mayor a un valor introducido.</p>\n<h1>Operador “Numeric Scorer?</h1>\n<p>Computa diferentes tipos de métricas como mean absolute error, mean squared error, root mean squared error, mean signed difference</p>\n<h2>Resultados</h2>\n<p><img src=\"https://github.com/JuanFKurucz/ia-portfolio/blob/main/content/posts/ut/ut4/pd/pd2/results.png?raw=true\" alt=\"results\"></p>","frontmatter":{"date":"2021-09-27","title":"Utilizando KNIME para árboles de decisión","tags":["Algoritmos no lineales","Arbol de decision","KNIME"],"cover":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAFYwwxmAAAACXBIWXMAAAPoAAAD6AG1e1JrAAABv0lEQVQ4y31TyVICMRDNT1sFxTZ78OYBRVEEXAC/yYullAI6gAhc236dhJoZkcMjnUwvr183qnr2TJX2O3m3X6Two4cb0qONuZTPJ6RwS/Di91PS4w01R8YFtgruluT3UsLHYLAUqFpnTqXWG+OVqpcfJntzvLVhW0o4KuFKmUcLKd1fUK37uc+J/Crgx9OnHUlEBrh7jJC/hyjus2GcTDrvcU0e1wvvVjbIUkfaU5Cx0K6vAtRJ+0VaqHWmIlapNZHWAO82lW/SYshlHCddBNMAhZhtaSbXNgMUwvuVOOpeKkE5x4hPyA1JQjhZMYVj0RHqOgV0bmCDpS25Fcd/u/ZtVzJdTJYr+IJUbFCJmK+qXE1lyvgQPXxLlzhj5hjjFKzNXd7MGfJ7xL5IVEeBLhfjN2X2yU7xCEUH+EVWXp+TxcMf0oMFNThHDIZIFmQTZmTHNocjTjBcm6CBWU03SydigtE4EZ0Gh9YXyfT9UjSLxjuZJzbaTORAR/uEHFBs2bDLF9gXPDo91rDB04PIAevhs+jBI5+MKLOizYKtD/y9hCGMhBO5ZW/wH7R+M/+D2vUsZwPYDrE7MypfTCT2F3D4YcZSRV9lAAAAAElFTkSuQmCC","aspectRatio":1.3994169096209912,"src":"/ia-portfolio/static/72db796afba268e3110fb0d733c943df/4359a/plot.png","srcSet":"/ia-portfolio/static/72db796afba268e3110fb0d733c943df/0d3b3/plot.png 480w,\n/ia-portfolio/static/72db796afba268e3110fb0d733c943df/263b6/plot.png 960w,\n/ia-portfolio/static/72db796afba268e3110fb0d733c943df/4359a/plot.png 1114w","srcWebp":"/ia-portfolio/static/72db796afba268e3110fb0d733c943df/3daac/plot.webp","srcSetWebp":"/ia-portfolio/static/72db796afba268e3110fb0d733c943df/83f4f/plot.webp 480w,\n/ia-portfolio/static/72db796afba268e3110fb0d733c943df/ce114/plot.webp 960w,\n/ia-portfolio/static/72db796afba268e3110fb0d733c943df/3daac/plot.webp 1114w","sizes":"(max-width: 1114px) 100vw, 1114px"},"resize":{"src":"/static/72db796afba268e3110fb0d733c943df/73f08/plot.png"}}}}}},"pageContext":{"pathSlug":"/pd/ut4/pd2","prev":{"frontmatter":{"path":"/ut/ut4/ta2","title":"Utilización de Árboles de decisión en RapidMiner","tags":["Algoritmos no lineales","Arbol de decision","RapidMiner","Performance","Accuracy","Gain ratio","Gini index","Information gain","eReader Dataset","Outliers","Target encoding","Normalizacion"]}},"next":{"frontmatter":{"path":"/pd/ut4/pd1","title":"Simulando el algoritmo CART en Excel","tags":["Algoritmos no lineales","CART","Excel"]}}}},"staticQueryHashes":["1830426702"]}