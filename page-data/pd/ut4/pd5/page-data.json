{"componentChunkName":"component---src-templates-post-jsx","path":"/pd/ut4/pd5","result":{"data":{"markdownRemark":{"html":"<p>En este artículo se comparan los algoritmos de árboles de decisión en RapidMiner vs los encontrados en la biblioteca Scikit-learn de Python.</p>\n<p>Se evaluaran los siguientes puntos:</p>\n<ul>\n<li>Tipos de problemas a que se pueden aplicar (clasificación o regresión, ejemplos)</li>\n<li>Algoritmos de base que utilizan</li>\n<li>Características requeridas a los atributos y a la variable objetivo</li>\n<li>Parámetros que aceptan, significado y opciones disponibles</li>\n</ul>\n<h1>RapidMiner</h1>\n<h2>Tipos de problemas a que se pueden aplicar</h2>\n<p>Se puede aplicar regresión y clasificación</p>\n<h2>Algoritmos de base que utilizan</h2>\n<p>No específica pero nombra ID3, Random Forest, CHAID y Bagging</p>\n<h2>Características requeridas a los atributos y a la variable objetivo</h2>\n<p>Atributos nominales y numéricos</p>\n<h2>Parámetros que aceptan, significado y opciones disponibles</h2>\n<ul>\n<li>Criterion: el criterio que se aplica para separar el árbol, se puede usar information<em>gain, gain</em>ratio, gini<em>index, accuracy, least</em>square</li>\n<li>Maximal depth: la altura máxima del árbol</li>\n<li>Apply pruning: si aplicar pruning o no, es decir si cortar el árbol en algunas ramas</li>\n<li>Confidence: hyper parámetro para el pruning</li>\n<li>Apply pre pruning: específica si se debe aplicar una parada previa al maximal depth</li>\n<li>Minimal gain: valor de división del cálculo de ganancia para cada split de nodos</li>\n<li>Minimal leaf size: tamaño de ejemplos que hay en cada hoja</li>\n<li>Minimal size for split: tamaño requerido para separar un nodo</li>\n<li>Number of pre pruning alternatives: cuantas alternativas a tomar en cuenta para aplicar pre pruning.</li>\n</ul>\n<h1>Python Scikit-learn</h1>\n<h2>Tipos de problemas a que se pueden aplicar</h2>\n<p>Se puede aplicar regresión y clasificación</p>\n<h2>Algoritmos de base que utilizan</h2>\n<p>ID3, C4.5, C5.0 y CART</p>\n<h2>Características requeridas a los atributos y a la variable objetivo</h2>\n<p>Atributos numéricos y categóricos</p>\n<h2>Parámetros que aceptan, significado y opciones disponibles</h2>\n<p>Classification:</p>\n<ul>\n<li>Criterion: {“gini”, “entropy”}, igual que en RapidMIner</li>\n<li>Splitter {“best”, “random”} la estrategia usada para separar cada nodo</li>\n<li>Max_depth: igual que en rapidminer</li>\n<li>Min<em>samples</em>split: igual que en rapidminer</li>\n<li>Min<em>samples</em>leaf: igual que en rapidminer</li>\n<li>Min<em>weight</em>fraction_leaf: el mínimo peso requerido para ser una hoja</li>\n<li>Max_features cantidad de características consideradas para conseguir el mejor split</li>\n<li>Random_state: establece el factor o semilla randomica</li>\n<li>Max<em>leaf</em>nodes: cantidad de hojas</li>\n<li>Min<em>impurity</em>decrease: participa en el cálculo impureza par realizar el split</li>\n<li>Class_weight: pesos relativos de clase para darle ponderación a cada clase.</li>\n<li>Ccp_alphanon-negative: parámetro de complejidad para aplicar pruning</li>\n</ul>\n<p>Regression:</p>\n<ul>\n<li>criterion{“squared<em>error”, “mse”, “friedman</em>mse”, “absolute_error”, “mae”, “poisson”}: igual que rapidminer</li>\n<li>Max_depth: igual que en rapidminer</li>\n<li>Min<em>samples</em>split: igual que en rapidminer</li>\n<li>Min<em>samples</em>leaf: igual que en rapidminer</li>\n<li>Min<em>weight</em>fraction_leaf: el mínimo peso requerido para ser una hoja</li>\n<li>Max_features cantidad de características consideradas para conseguir el mejor split</li>\n<li>Random_state: establece el factor o semilla randomica</li>\n<li>Max<em>leaf</em>nodes: cantidad de hojas</li>\n<li>Min<em>impurity</em>decrease: participa en el cálculo impureza par realizar el split</li>\n<li>Ccp_alphanon-negative: parámetro de complejidad para aplicar pruning</li>\n</ul>\n<h1>Conclusiones</h1>\n<p>Como conclusión podemos ver que ambos contienen los mismos parámetros y aplican algoritmos parecidos.</p>","frontmatter":{"date":"2021-10-08","title":"Arboles de decision en RapidMiner vs Python Scikit Learn","tags":["Algoritmos no lineales","Árbol de decisión","RapidMiner","Python","Scikit-learn"],"cover":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAgAD/8QAFwEAAwEAAAAAAAAAAAAAAAAAAAEDBP/aAAwDAQACEAMQAAABks9cXCF//8QAGhAAAgIDAAAAAAAAAAAAAAAAAQIAERASIv/aAAgBAQABBQI3SnnYxs//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAVEAEBAAAAAAAAAAAAAAAAAAARIP/aAAgBAQAGPwJr/8QAGxABAAICAwAAAAAAAAAAAAAAAQAREFEhMUH/2gAIAQEAAT8hIYOoPKqZoi82Z//aAAwDAQACAAMAAAAQQO//xAAWEQEBAQAAAAAAAAAAAAAAAAABEQD/2gAIAQMBAT8QoE1d/8QAFhEBAQEAAAAAAAAAAAAAAAAAABEx/9oACAECAQE/ENR//8QAHBABAAEEAwAAAAAAAAAAAAAAAREAITFBEFFh/9oACAEBAAE/EA4OwuDunBiWIN1ebAXEU44Rc95//9k=","aspectRatio":1.6216216216216217,"src":"/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/7c424/blocks.jpg","srcSet":"/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/6b948/blocks.jpg 480w,\n/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/d1e22/blocks.jpg 960w,\n/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/7c424/blocks.jpg 1525w","srcWebp":"/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/de750/blocks.webp","srcSetWebp":"/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/83f4f/blocks.webp 480w,\n/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/ce114/blocks.webp 960w,\n/ia-portfolio/static/3e8b4c0e1152436f37932c914c93f96e/de750/blocks.webp 1525w","sizes":"(max-width: 1525px) 100vw, 1525px"},"resize":{"src":"/static/3e8b4c0e1152436f37932c914c93f96e/a6c62/blocks.jpg"}}}}}},"pageContext":{"pathSlug":"/pd/ut4/pd5","prev":{"frontmatter":{"path":"/ut/ut4/ta6","title":"Utilización de Supported Vector Machines en RapidMiner","tags":["Algoritmos no lineales","Supported Vector Machines","RapidMiner"]}},"next":{"frontmatter":{"path":"/pd/ut4/pd3","title":"Simulando el algoritmo de Supported Vector Machines en Excel","tags":["Algoritmos no lineales","Supported Vector Machines","Excel"]}}}},"staticQueryHashes":["1830426702"]}